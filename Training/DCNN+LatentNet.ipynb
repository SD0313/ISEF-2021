{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3c05ef44-82d0-4cde-b40a-c2b75cfa8a87",
    "_uuid": "75535264-e181-4495-b9ea-80408a946318"
   },
   "outputs": [],
   "source": [
    "import mitdeeplearning as mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "acb09328-c34e-4057-9dcf-6c6e970a17b4",
    "_uuid": "0dbc42e7-994c-408f-97c7-3df007ee6307"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import layers as L\n",
    "import tensorflow.keras.preprocessing.image as imgPrep\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "###Constant###\n",
    "EPOCHS = 25\n",
    "SMOOTHING_FAC = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "62031a3a-0dee-4a90-a819-f009e023391b",
    "_uuid": "00ee325d-1242-4426-b634-4479804c562c"
   },
   "outputs": [],
   "source": [
    "data_path = r'C:\\Fairfax SEF\\short_data.h5'\n",
    "cache = h5py.File(data_path, 'r')\n",
    "images = cache['images'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3f458bfd-27f5-43c9-aaae-97b0dccc68c9",
    "_uuid": "0be85af5-3e7f-4ac1-b75b-a44e8d00cc04"
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0aa32633-699f-4034-9d59-73d667d5e5ef",
    "_uuid": "e57dd54e-952b-467c-957d-ec7f9d6abf78"
   },
   "outputs": [],
   "source": [
    "labels = cache['labels'][:].astype(np.float32)\n",
    "labels = labels.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d71df9ab-c484-41e2-86be-229495897a19",
    "_uuid": "d093d7fb-9f9f-4efb-acce-f2e7b1e1aec3"
   },
   "outputs": [],
   "source": [
    "number_of_training_examples = images.shape[0]\n",
    "image_dims = images.shape\n",
    "n_train_samples = image_dims[0]\n",
    "train_inds = np.random.permutation(np.arange(n_train_samples))\n",
    "pos_train_inds = train_inds[labels[train_inds, 0] == 1.0 ]\n",
    "neg_train_inds = train_inds[labels[train_inds, 0] != 1.0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cd343493-9a4b-4e60-b290-34c8539a6962",
    "_uuid": "dba1dd7a-344d-4549-a0ab-038319797eba"
   },
   "outputs": [],
   "source": [
    "def get_batch(n, only_faces=False, p_pos=None, p_neg=None, return_inds=False):\n",
    "    if only_faces:\n",
    "            selected_inds = np.random.choice(pos_train_inds, size=n, replace=False, p=p_pos)\n",
    "    else:\n",
    "        selected_pos_inds = np.random.choice(pos_train_inds, size=n//2, replace=False, p=p_pos)\n",
    "        selected_neg_inds = np.random.choice(neg_train_inds, size=n//2, replace=False, p=p_neg)\n",
    "        selected_inds = np.concatenate((selected_pos_inds, selected_neg_inds))\n",
    "    sorted_inds = np.sort(selected_inds)\n",
    "    train_img = (images[sorted_inds,:,:,::]).astype(np.float32)\n",
    "    train_label = labels[sorted_inds,...]\n",
    "    return (train_img, train_label, sorted_inds) if return_inds else (train_img, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5dd57a31-8905-4626-a705-6bd91a0175f4",
    "_uuid": "aef284c7-240b-4bda-a2c9-8361d06aa5ef"
   },
   "outputs": [],
   "source": [
    "n_filters=12\n",
    "def make_standard_classifier(n_outputs=1):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(L.Conv2D(filters=1*n_filters, kernel_size=5, \n",
    "                       strides=2, padding='same', activation='relu'))\n",
    "    model.add(L.BatchNormalization())\n",
    "\n",
    "    model.add(L.Conv2D(filters=2*n_filters, kernel_size=5, \n",
    "                       strides=2, padding='same', activation='relu'))\n",
    "    model.add(L.BatchNormalization())\n",
    "\n",
    "    model.add(L.Conv2D(filters=4*n_filters, kernel_size=5, \n",
    "                       strides=2, padding='same', activation='relu'))\n",
    "    model.add(L.BatchNormalization())\n",
    "\n",
    "    model.add(L.Conv2D(filters=6*n_filters, kernel_size=5, \n",
    "                       strides=2, padding='same', activation='relu'))\n",
    "    model.add(L.BatchNormalization())\n",
    "\n",
    "    model.add(L.Conv2D(filters=8*n_filters, kernel_size=5, \n",
    "                       strides=2, padding='same', activation='relu'))\n",
    "    model.add(L.BatchNormalization())\n",
    "\n",
    "    model.add(L.Flatten())\n",
    "    model.add(L.Dense(512))\n",
    "    model.add(L.Dense(n_outputs, activation=None))\n",
    "    return model\n",
    "model = make_standard_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7da96968-e2a0-47e2-88df-91ba1f9f1aad",
    "_uuid": "789a201e-0725-45b0-a7ac-20e6eee7d0d7"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = EPOCHS \n",
    "learning_rate = 5e-4\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate) \n",
    "loss_history = mdl.util.LossHistory(smoothing_factor=0.99) \n",
    "plotter = mdl.util.PeriodicPlotter(sec=2, scale='semilogy')\n",
    "if hasattr(tqdm, '_instances'): tqdm._instances.clear() \n",
    "\n",
    "    \n",
    "@tf.function\n",
    "def standard_train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # feed the images into the model\n",
    "        logits = model(x) \n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "        print(loss)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# The training loop!\n",
    "for epoch in range(num_epochs):\n",
    "    for idx in tqdm(range(n_train_samples//batch_size)):\n",
    "        # Grab a batch of training data and propagate through the network\n",
    "        x, y = get_batch(batch_size)\n",
    "        loss = standard_train_step(x, y)\n",
    "\n",
    "        # Record the loss and plot the evolution of the loss as a function of training\n",
    "        loss_history.append(loss.numpy().mean())\n",
    "        plotter.plot(loss_history.get())\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "96132451-fc19-479b-b41b-ffb3f1e95c9c",
    "_uuid": "dbc85b4e-8c5b-4993-aa2a-b351a17ba25b"
   },
   "outputs": [],
   "source": [
    "(batch_x, batch_y) = get_batch(1000)\n",
    "y_pred_standard = tf.round(tf.nn.sigmoid(model.predict(batch_x)))\n",
    "acc_standard = tf.reduce_mean(tf.cast(tf.equal(batch_y, y_pred_standard), tf.float32))\n",
    "\n",
    "print(\"Standard CNN accuracy on (potentially biased) training set: {:.4f}\".format(acc_standard.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6e63f4b4-8224-421e-acd7-2c03123b2ed1",
    "_uuid": "a00eb099-76cd-43fb-b480-1531e9b0cf78"
   },
   "outputs": [],
   "source": [
    "def vae_loss_function(x, x_recon, mu, logsigma, kl_weight=0.0005):\n",
    "\n",
    "    latent_loss = tf.reduce_sum(tf.exp(logsigma)+mu**2-1-logsigma, axis=1)*0.5\n",
    "\n",
    "\n",
    "    reconstruction_loss = tf.reduce_mean(tf.abs(x-x_recon), axis=(1, 2, 3))\n",
    "\n",
    "    vae_loss = kl_weight*latent_loss+reconstruction_loss\n",
    "\n",
    "    return vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a590e5db-247d-4167-b079-ae91d71342d8",
    "_uuid": "7c4dd80d-1047-4589-803e-1cc3c8d6527e"
   },
   "outputs": [],
   "source": [
    "def sampling(z_mean, z_logsigma):\n",
    "    batch, latent_dim = z_mean.shape\n",
    "    epsilon = tf.random.normal(shape=(batch, latent_dim))\n",
    "\n",
    "    z = z_mean+tf.exp(0.5*z_logsigma)*epsilon\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bf8ea012-f9e6-4955-9cde-309de77f1025",
    "_uuid": "2e44a9e2-1e62-4da6-b500-fe5604b0c64f"
   },
   "outputs": [],
   "source": [
    "def debiasing_loss_function(x, x_pred, y, y_logit, mu, logsigma):\n",
    "\n",
    "    vae_loss = vae_loss_function(x, x_pred, mu, logsigma)\n",
    "\n",
    "\n",
    "    classification_loss = tf.nn.sigmoid_cross_entropy_with_logits(y, y_logit)\n",
    "\n",
    "\n",
    "    mel_indicator = tf.cast(tf.equal(y, 1), tf.float32)\n",
    "\n",
    "\n",
    "    total_loss = classification_loss+mel_indicator*vae_loss\n",
    "\n",
    "    return total_loss, classification_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "84b8f999-cb13-44b1-8117-bd4abec60365",
    "_uuid": "e415fa5c-fdf8-4d0b-b922-6bcece75cd47"
   },
   "outputs": [],
   "source": [
    "n_filters = 12 # base number of convolutional filters, same as standard CNN\n",
    "latent_dim = 100 # number of latent variables\n",
    "\n",
    "def make_face_decoder_network():\n",
    "    # Functionally define the different layer types we will use\n",
    "\n",
    "    # Build the decoder network using the Sequential API\n",
    "    decoder = tf.keras.Sequential([\n",
    "    # Transform to pre-convolutional generation\n",
    "    L.Dense(units=8*8*8*n_filters, activation='relu'),  # 4x4 feature maps (with 6N occurances)\n",
    "    L.Reshape(target_shape=(8, 8, 8*n_filters)),\n",
    "\n",
    "    # Upscaling convolutions (inverse of encoder)\n",
    "    L.Conv2DTranspose(filters=6*n_filters, kernel_size=5,  strides=2, padding='same', activation='relu'),\n",
    "    L.Conv2DTranspose(filters=4*n_filters, kernel_size=5,  strides=2, padding='same', activation='relu'),\n",
    "    L.Conv2DTranspose(filters=2*n_filters, kernel_size=5,  strides=2, padding='same', activation='relu'),\n",
    "    L.Conv2DTranspose(filters=1*n_filters, kernel_size=5,  strides=2, padding='same', activation='relu'),\n",
    "    L.Conv2DTranspose(filters=3, kernel_size=5,  strides=2, padding='same', activation='relu'),\n",
    "    ])\n",
    "\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "be60601c-96d9-40f7-984b-3967411448e7",
    "_uuid": "e3d0c8a0-144a-4dcc-990e-99da51564a94"
   },
   "outputs": [],
   "source": [
    "class LatentNet(tf.keras.Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(LatentNet, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "\n",
    "    # Define the number of outputs for the encoder. Recall that we have \n",
    "    # `latent_dim` latent variables, as well as a supervised output for the \n",
    "    # classification.\n",
    "    num_encoder_dims = 2*self.latent_dim + 1\n",
    "\n",
    "    self.encoder = make_standard_classifier(num_encoder_dims)\n",
    "    self.decoder = make_face_decoder_network()\n",
    "\n",
    "  # function to feed images into encoder, encode the latent space, and output\n",
    "  #   classification probability \n",
    "  def encode(self, x):\n",
    "    # encoder output\n",
    "    encoder_output = self.encoder(x)\n",
    "\n",
    "    # classification prediction\n",
    "    y_logit = tf.expand_dims(encoder_output[:, 0], -1)\n",
    "    # latent variable distribution parameters\n",
    "    z_mean = encoder_output[:, 1:self.latent_dim+1] \n",
    "    z_logsigma = encoder_output[:, self.latent_dim+1:]\n",
    "\n",
    "    return y_logit, z_mean, z_logsigma\n",
    "\n",
    "  # VAE reparameterization: given a mean and logsigma, sample latent variables\n",
    "  def reparameterize(self, z_mean, z_logsigma):\n",
    "    z = sampling(z_mean, z_logsigma)\n",
    "    return z\n",
    "\n",
    "  # Decode the latent space and output reconstruction\n",
    "  def decode(self, z):\n",
    "    reconstruction = self.decoder(z)\n",
    "    return reconstruction\n",
    "\n",
    "  def call(self, x): \n",
    "    y_logit, z_mean, z_logsigma = self.encode(x)\n",
    "\n",
    "    z = self.reparameterize(z_mean, z_logsigma)\n",
    "\n",
    "    recon = self.decode(z)\n",
    "    return y_logit, z_mean, z_logsigma, recon\n",
    "\n",
    "  def predict(self, x):\n",
    "    y_logit, z_mean, z_logsigma = self.encode(x)\n",
    "    return y_logit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6d6c0c06-8570-45f3-8139-27b7d0bc842b",
    "_uuid": "6e9a4e90-e43b-4163-8269-cae8747ee07a"
   },
   "outputs": [],
   "source": [
    "def get_latent_mu(images, latent_net, batch_size=1024):\n",
    "  N = images.shape[0]\n",
    "  mu = np.zeros((N, latent_dim))\n",
    "  for start_ind in range(0, N, batch_size):\n",
    "    end_ind = min(start_ind+batch_size, N+1)\n",
    "    batch = (images[start_ind:end_ind]).astype(np.float32)/255.\n",
    "    _, batch_mu, _ = latent_net.encode(batch)\n",
    "    mu[start_ind:end_ind] = batch_mu\n",
    "  return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1394e16d-9150-4dca-8f8c-f3764b386847",
    "_uuid": "7e9d6826-79c7-4fc1-b055-35a2c42fbdff"
   },
   "outputs": [],
   "source": [
    "'''Function that recomputes the sampling probabilities for images within a batch\n",
    "      based on how they distribute across the training data'''\n",
    "def get_training_sample_probabilities(images, latent_net, bins=10, smoothing_fac=SMOOTHING_FAC): \n",
    "    print(\"Recomputing the sampling probabilities\")\n",
    "    \n",
    "    mu = get_latent_mu(images, latent_net) # TODO\n",
    "\n",
    "    # sampling probabilities for the images\n",
    "    training_sample_p = np.zeros(mu.shape[0])\n",
    "    \n",
    "    for i in range(latent_dim):\n",
    "      \n",
    "        latent_distribution = mu[:,i]\n",
    "        hist_density, bin_edges =  np.histogram(latent_distribution, density=True, bins=bins)\n",
    "\n",
    "        bin_edges[0] = -float('inf')\n",
    "        bin_edges[-1] = float('inf')\n",
    "        \n",
    "\n",
    "        bin_idx = np.digitize(latent_distribution, bin_edges) \n",
    "        hist_smoothed_density = hist_density + smoothing_fac\n",
    "        hist_smoothed_density = hist_smoothed_density / np.sum(hist_smoothed_density)\n",
    "\n",
    "        p = 1.0/(hist_smoothed_density[bin_idx-1])\n",
    "        p = p/np.sum(p)\n",
    "        training_sample_p = np.maximum(p, training_sample_p)\n",
    "        break\n",
    "        \n",
    "    # final normalization\n",
    "    training_sample_p /= np.sum(training_sample_p)\n",
    "\n",
    "    return training_sample_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eae42117-d03b-45d6-9ca8-b358903c0331",
    "_uuid": "b71a333a-b310-400d-ba8f-d9df87412e39"
   },
   "outputs": [],
   "source": [
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eaf32a4f-e962-4076-b87f-186ba409c899",
    "_uuid": "f6c91be3-1407-4d4e-bb8e-74dc6ab79651"
   },
   "outputs": [],
   "source": [
    "### Training the LatentNet ###\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 5e-4\n",
    "latent_dim = 100\n",
    "\n",
    "\n",
    "num_epochs = EPOCHS \n",
    "\n",
    "latent_net = LatentNet(latent_dim)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def debiasing_train_step(x, y):\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    y_logit, z_mean, z_logsigma, x_recon = latent_net(x)\n",
    "\n",
    "    loss, class_loss = debiasing_loss_function(x, x_recon, y, y_logit, z_mean, z_logsigma)\n",
    "\n",
    "  grads = tape.gradient(loss, latent_net.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(grads, latent_net.trainable_variables))\n",
    "  return loss\n",
    "\n",
    "# get training faces from data loader\n",
    "all_mel = images[pos_train_inds]\n",
    "\n",
    "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
    "\n",
    "# The training loop -- outer loop iterates over the number of epochs\n",
    "for i in range(num_epochs):\n",
    "\n",
    "  IPython.display.clear_output(wait=True)\n",
    "  print(\"Starting epoch {}/{}\".format(i+1, num_epochs))\n",
    "\n",
    "  # Recompute data sampling proabilities\n",
    "  '''TODO: recompute the sampling probabilities for debiasing'''\n",
    "  p_mel = get_training_sample_probabilities(all_mel, latent_net) \n",
    "  \n",
    "  # get a batch of training data and compute the training step\n",
    "  for j in tqdm(range(n_train_samples // batch_size)):\n",
    "    # load a batch of data\n",
    "    (x, y) = get_batch(batch_size, p_pos=p_mel)\n",
    "    # loss optimization\n",
    "    loss = debiasing_train_step(x, y)\n",
    "    \n",
    "    # plot the progress every 200 steps\n",
    "    if j % 500 == 0: \n",
    "      mdl.util.plot_sample(x, y, latent_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b843fb11-7a1f-4b37-9ed3-1d61ee4c9d9c",
    "_uuid": "807f46ef-3a27-40cd-90b3-f3d7b99fa23c"
   },
   "outputs": [],
   "source": [
    "latent_net_logits = [latent_net.predict(np.array(x.reshape(1, 256, 256, 3), dtype=np.float32)) for x in batch_x]\n",
    "latent_net_probs = tf.squeeze(tf.sigmoid(latent_net_logits))\n",
    "preds = [np.array([1.0]) if pred > 0.5 else np.array([0.0]) for pred in latent_net_probs]\n",
    "preds = np.array(preds)\n",
    "acc_standard = tf.reduce_mean(tf.cast(tf.equal(batch_y, preds), tf.float32))\n",
    "\n",
    "print(\"LatentNet accuracy on training set: {:.4f}\".format(acc_standard.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2682d185-8c19-4ef3-8808-00f3c5f4b29b",
    "_uuid": "46ef4566-105a-4bcc-9387-048778b3ca67"
   },
   "outputs": [],
   "source": [
    "def test(path):\n",
    "    latent_net_preds = []\n",
    "    reg_preds = []\n",
    "    for img in os.listdir(path):\n",
    "        full_path = os.path.join(path, img)\n",
    "        loaded = imgPrep.load_img(full_path, target_size=(256, 256))\n",
    "        arr = imgPrep.img_to_array(loaded)/255.0\n",
    "        pred1 = tf.sigmoid(latent_net.predict(arr.reshape(1, 256, 256, 3)))\n",
    "        pred2 = tf.sigmoid(model.predict(arr.reshape(1, 256, 256, 3)))\n",
    "        latent_net_preds.append(np.array(pred1)[0][0]); reg_preds.append(np.array(pred2)[0][0])\n",
    "    print(f'LatentNet Confidence: {sum(latent_net_preds)/len(latent_net_preds)}')\n",
    "    print(f'Standard Confidence: {sum(reg_preds)/len(reg_preds)}')\n",
    "    return latent_net_preds, reg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "73759cca-5d96-4a84-b1c7-c1ffb2a0a14f",
    "_uuid": "de0ed568-22ec-46d6-b32f-1494dc301a7d"
   },
   "outputs": [],
   "source": [
    "version = '5'\n",
    "normal_hair = f'../input/melanoma-h5-dataset/---Full Validation Sets---v{version}/---Full Validation Sets---/Hair Density/Normal'\n",
    "mel_hair = f'../input/melanoma-h5-dataset/---Full Validation Sets---v{version}/---Full Validation Sets---/Hair Density/Melanoma'\n",
    "normal_type_1 = f'../input/melanoma-h5-dataset/---Full Validation Sets---v{version}/---Full Validation Sets---/Skin Type/Normal/Type I'\n",
    "mel_type_1 = f'../input/melanoma-h5-dataset/---Full Validation Sets---v{version}/---Full Validation Sets---/Skin Type/Melanoma/Type I'\n",
    "normal_type_2 = f'../input/melanoma-h5-dataset/---Full Validation Sets---v{version}/---Full Validation Sets---/Skin Type/Normal/Type II'\n",
    "mel_type_2 = f'../input/melanoma-h5-dataset/---Full Validation Sets---v{version}/---Full Validation Sets---/Skin Type/Melanoma/Type II'\n",
    "normal_type_3 = f'../input/melanoma-h5-dataset/---Full Validation Sets---v{version}/---Full Validation Sets---/Skin Type/Normal/Type III'\n",
    "mel_type_3 = f'../input/melanoma-h5-dataset/---Full Validation Sets---v{version}/---Full Validation Sets---/Skin Type/Melanoma/Type III'\n",
    "normal_regions = f'../input/melanoma-h5-dataset/---Full Validation Sets---v{version}/---Full Validation Sets---/Anatomical Site/Normal'\n",
    "mel_regions = f'../input/melanoma-h5-dataset/---Full Validation Sets---v{version}/---Full Validation Sets---/Anatomical Site/Melanoma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "94b26125-1c50-4dd9-8889-c36df76cf017",
    "_uuid": "8cf529d9-dc91-429e-9361-0e56008d2709"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def get_acc(norm_path, mel_path, db_w=0.5, reg_w=0.5):\n",
    "    norm_imgs = [os.path.join(norm_path, img) for img in os.listdir(norm_path)]\n",
    "    mel_imgs = [os.path.join(mel_path, img) for img in os.listdir(mel_path)]\n",
    "    correct_db = 0\n",
    "    correct_norm = 0\n",
    "    correct_ensemble = 0\n",
    "    db_preds = []\n",
    "    norm_preds = []\n",
    "    ens_preds = []\n",
    "    tru_preds = []\n",
    "    for i, img in enumerate(norm_imgs):\n",
    "        loaded = imgPrep.load_img(img, target_size=(256, 256))\n",
    "        arr = imgPrep.img_to_array(loaded)/255.\n",
    "        pred1 = tf.sigmoid(latent_net.predict(arr.reshape(1, 256, 256, 3)))\n",
    "        pred2 = tf.sigmoid(model.predict(arr.reshape(1, 256, 256, 3)))\n",
    "        correct_db += int(pred1 < 0.5)\n",
    "        correct_norm += int(pred2 < 0.5)\n",
    "        ens_pred = db_w*pred1+(reg_w*pred2)\n",
    "        correct_ensemble += int(ens_pred < 0.5)\n",
    "        norm_preds.append(np.array(pred2)[0][0]); db_preds.append(np.array(pred1)[0][0]);\n",
    "        ens_preds.append(np.array(ens_pred)[0][0])\n",
    "        tru_preds.append(0)\n",
    "    for i, img in enumerate(mel_imgs):\n",
    "        loaded = imgPrep.load_img(img, target_size=(256, 256))\n",
    "        arr = imgPrep.img_to_array(loaded)/255.\n",
    "        pred1 = tf.sigmoid(latent_net.predict(arr.reshape(1, 256, 256, 3)))\n",
    "        pred2 = tf.sigmoid(model.predict(arr.reshape(1, 256, 256, 3)))\n",
    "        correct_db += int(pred1 >= 0.5)\n",
    "        correct_norm += int(pred2 >= 0.5)  \n",
    "        ens_pred = db_w*pred1+(reg_w*pred2)\n",
    "        correct_ensemble += int(ens_pred >= 0.5)\n",
    "        norm_preds.append(np.array(pred2)[0][0]); db_preds.append(np.array(pred1)[0][0]);\n",
    "        ens_preds.append(np.array(ens_pred)[0][0])\n",
    "        tru_preds.append(1)\n",
    "    norm_auc = roc_auc_score(tru_preds, norm_preds)\n",
    "    db_auc = roc_auc_score(tru_preds, db_preds)\n",
    "    ens_auc = roc_auc_score(tru_preds, ens_preds)\n",
    "    total_imgs = (len(norm_imgs)+len(mel_imgs))\n",
    "    print(f'LatentNet Accuracy: {correct_db/total_imgs}, AUC: {db_auc}')\n",
    "    print(f'Standard Accuracy: {correct_norm/total_imgs}, AUC: {norm_auc}')\n",
    "    print(f'Ensemble Accuracy: {correct_ensemble/total_imgs}, AUC: {ens_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc(normal_regions, mel_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eef71c86-f459-45c7-9e8d-508590d6fbe0",
    "_uuid": "8b44dd25-3863-4251-a603-ad2bf77e28f1"
   },
   "outputs": [],
   "source": [
    "get_acc(normal_hair, mel_hair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "56885e34-d70d-41b5-b004-5d157a90596c",
    "_uuid": "c6e03a42-20e6-42eb-98f4-7be2b6c0b3c7"
   },
   "outputs": [],
   "source": [
    "get_acc(normal_type_1, mel_type_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "64149f96-f602-4b09-b30e-a44a4d05ca2f",
    "_uuid": "790feb81-1d98-432b-bfef-e83a336b0b16"
   },
   "outputs": [],
   "source": [
    "get_acc(normal_type_2, mel_type_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ab740d17-b9dc-4274-bc52-168ed197cb1c",
    "_uuid": "4c207bac-b118-4808-9290-2ebc6a6b4336"
   },
   "outputs": [],
   "source": [
    "get_acc(normal_type_3, mel_type_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
